{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe76661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mido\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a24614",
   "metadata": {},
   "source": [
    "# Note Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Note:\n",
    "    def __init__(self, pitch, instrument, start, duration, dict_key):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "            - pitch: MIDI pitch (int)\n",
    "            - instrument\n",
    "            - start: start time (int)\n",
    "            - end: end time (int)\n",
    "        \n",
    "        fields:\n",
    "            - interval: wrt = (pitch-key) % 12\n",
    "            - tags: set of strings, flexible labeling\n",
    "        \"\"\"\n",
    "        self.pitch = pitch # MIDI pitch\n",
    "        self.start = start\n",
    "        self.duration = duration\n",
    "        self.instrument = instrument\n",
    "        self.dict_key = dict_key\n",
    "\n",
    "        # self.interval = pitch \n",
    "        self.key = None\n",
    "        self.chord = False\n",
    "\n",
    "        self.track_number = None\n",
    "        \n",
    "        # motif, repetition, rigid/rubato\n",
    "        self.tags = set()\n",
    "\n",
    "    def add_tag(self, tag: str):\n",
    "        self.tags.add(tag)\n",
    "\n",
    "    def set_key_and_interval(self, key):\n",
    "        self.key = key\n",
    "        self.interval = abs(self.pitch-key) % 12\n",
    "    \n",
    "    def set_melody(self, is_melody):\n",
    "        self.melody = is_melody\n",
    "    \n",
    "    def set_chord(self, is_chord):\n",
    "        self.chord = is_chord\n",
    "\n",
    "    def set_track_number(self, track_number: int):\n",
    "        self.track_number = track_number\n",
    "    \n",
    "    def get_track_number(self):\n",
    "        return self.track_number\n",
    "    \n",
    "    def get_start_time(self):\n",
    "        return self.start\n",
    "    \n",
    "    def get_duration(self):\n",
    "        return self.duration\n",
    "\n",
    "    def get_dict_key(self):\n",
    "        return self.dict_key\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Note(pitch={self.pitch}, start={self.start}, duration={self.duration}, instrument={self.instrument}, dict_key={self.dict_key}, track_number={self.track_number})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a56ad7",
   "metadata": {},
   "source": [
    "# Pre-Processing Functions + Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e412c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration variables from original repo \n",
    "\n",
    "MAX_TIME_IN_SECONDS = 100          # exclude very long training sequences\n",
    "MAX_DURATION_IN_SECONDS = 10       # maximum duration of a note\n",
    "TIME_RESOLUTION = 100 # ticks per second\n",
    "\n",
    "MAX_PITCH = 128                    # 128 MIDI pitches\n",
    "MAX_INSTR = 129                    # 129 MIDI instruments (128 + drums)\n",
    "MAX_NOTE = MAX_PITCH*MAX_INSTR     # note = pitch x instrument\n",
    "\n",
    "MAX_TIME = TIME_RESOLUTION*MAX_TIME_IN_SECONDS\n",
    "MAX_DUR = TIME_RESOLUTION*MAX_DURATION_IN_SECONDS\n",
    "\n",
    "EVENT_OFFSET = 0\n",
    "TIME_OFFSET = EVENT_OFFSET\n",
    "DUR_OFFSET = TIME_OFFSET + MAX_TIME\n",
    "NOTE_OFFSET = DUR_OFFSET + MAX_DUR\n",
    "REST = NOTE_OFFSET + MAX_NOTE\n",
    "\n",
    "CONTROL_OFFSET = NOTE_OFFSET + MAX_NOTE + 1\n",
    "ATIME_OFFSET = CONTROL_OFFSET + 0\n",
    "ADUR_OFFSET = ATIME_OFFSET + MAX_TIME\n",
    "ANOTE_OFFSET = ADUR_OFFSET + MAX_DUR\n",
    "\n",
    "# the special block\n",
    "SPECIAL_OFFSET = ANOTE_OFFSET + MAX_NOTE\n",
    "SEPARATOR = SPECIAL_OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c66464",
   "metadata": {},
   "outputs": [],
   "source": [
    "### modified repo code to parse MIDI file for tokens\n",
    "\n",
    "def midi_to_compound(midifile, debug=False):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - midifile: MIDI file (all tracks)\n",
    "\n",
    "    returns:\n",
    "        - list of tokens in the pattern: (start time, duration, MIDI note, instrument, velocity, channel)\n",
    "        - list of keys of notes: (instrument, note, channel, onset_time_in_ticks, duration_ticks)\n",
    "            - correspond 1:6 with the notes in the tokens\n",
    "    \"\"\"\n",
    "    if type(midifile) == str:\n",
    "        midi = mido.MidiFile(midifile)\n",
    "    else:\n",
    "        midi = midifile\n",
    "\n",
    "    tokens = []\n",
    "    note_idx = 0\n",
    "    open_notes = defaultdict(list)\n",
    "    closed_notes = []\n",
    "\n",
    "    time = 0\n",
    "    instruments = defaultdict(int) # default to code 0 = piano\n",
    "    tempo = 500000 # default tempo: 500000 microseconds per beat\n",
    "\n",
    "    for message in midi:\n",
    "        time += message.time\n",
    "        # print(\"MESSAGE\", message, round(TIME_RESOLUTION*time))\n",
    "\n",
    "        # sanity check: negative time?\n",
    "        if message.time < 0:\n",
    "            raise ValueError\n",
    "\n",
    "        if message.type == 'program_change':\n",
    "            instruments[message.channel] = message.program\n",
    "        elif message.type in ['note_on', 'note_off']:\n",
    "            # special case: channel 9 is drums!\n",
    "            instr = 128 if message.channel == 9 else instruments[message.channel]\n",
    "\n",
    "            if message.type == 'note_on' and message.velocity > 0: # onset\n",
    "                # time quantization\n",
    "                time_in_ticks = round(TIME_RESOLUTION*time)\n",
    "                # print(time, time_in_ticks)\n",
    "\n",
    "                # Our compound word is: (time, duration, note, instr, velocity)\n",
    "                tokens.append(time_in_ticks) # 5ms resolution\n",
    "                tokens.append(-1) # placeholder (we'll fill this in later)\n",
    "                tokens.append(message.note)\n",
    "                tokens.append(instr)\n",
    "                tokens.append(message.velocity)\n",
    "\n",
    "                tokens.append(message.channel) # CHANNEL INFO FOR KEY\n",
    "\n",
    "                open_notes[(instr,message.note,message.channel)].append((note_idx, time))\n",
    "                note_idx += 1\n",
    "            else: # offset\n",
    "                try:\n",
    "                    open_idx, onset_time = open_notes[(instr,message.note,message.channel)].pop(0)\n",
    "                except IndexError:\n",
    "                    if debug:\n",
    "                        print('WARNING: ignoring bad offset')\n",
    "                else:\n",
    "                    duration_ticks = round(TIME_RESOLUTION*(time-onset_time))\n",
    "                    # tokens[5*open_idx + 1] = duration_ticks\n",
    "                    tokens[6*open_idx + 1] = duration_ticks # ACCOUNT FOR CHANNEL\n",
    "                    # print(\"onset time:\", onset_time, \"duration_ticks:\", duration_ticks)\n",
    "                    onset_time_in_ticks = round(TIME_RESOLUTION*onset_time)\n",
    "\n",
    "                    # closed_notes[(instr,message.note, message.channel, onset_time_in_ticks, duration_ticks)].append(\"\")\n",
    "                    closed_notes.append((instr,message.note, message.channel, onset_time_in_ticks, duration_ticks))\n",
    "\n",
    "                    #del open_notes[(instr,message.note,message.channel)]\n",
    "        elif message.type == 'set_tempo':\n",
    "            tempo = message.tempo\n",
    "        elif message.type == 'time_signature':\n",
    "            # print('TIME SIGNATURE', message)\n",
    "            pass # we use real time\n",
    "        elif message.type in ['aftertouch', 'polytouch', 'pitchwheel', 'sequencer_specific']:\n",
    "            pass # we don't attempt to model these\n",
    "        elif message.type == 'control_change':\n",
    "            pass # this includes pedal and per-track volume: ignore for now\n",
    "        elif message.type in ['track_name', 'text', 'end_of_track', 'lyrics', 'key_signature',\n",
    "                              'copyright', 'marker', 'instrument_name', 'cue_marker',\n",
    "                              'device_name', 'sequence_number']:\n",
    "            pass # possibly useful metadata but ignore for now\n",
    "        elif message.type == 'channel_prefix':\n",
    "            pass # relatively common, but can we ignore this?\n",
    "        elif message.type in ['midi_port', 'smpte_offset', 'sysex']:\n",
    "            pass # I have no idea what this is\n",
    "        else:\n",
    "            if debug:\n",
    "                print('UNHANDLED MESSAGE', message.type, message)\n",
    "        # print(tokens)\n",
    "\n",
    "    unclosed_count = 0\n",
    "    for _,v in open_notes.items():\n",
    "        unclosed_count += len(v)\n",
    "\n",
    "    if debug and unclosed_count > 0:\n",
    "        print(f'WARNING: {unclosed_count} unclosed notes')\n",
    "        print('  ', midifile)\n",
    "\n",
    "    return tokens, closed_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b8aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_tracks_to_dict(track_midifile, track_num, debug=False):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - track_midifile: MIDI file (single track)\n",
    "        - track_num: the track number (int)\n",
    "\n",
    "    returns a dictionary of notes with:\n",
    "        - key = (instrument, note, channel, onset_time_in_ticks, duration_ticks)\n",
    "        - value = track number\n",
    "    \"\"\"\n",
    "    if type(track_midifile) == str:\n",
    "        midi = mido.MidiFile(track_midifile)\n",
    "    else:\n",
    "        midi = track_midifile\n",
    "\n",
    "    tokens = []\n",
    "    note_idx = 0\n",
    "    open_notes = defaultdict(list)\n",
    "    closed_notes = defaultdict(int)\n",
    "\n",
    "    time = 0\n",
    "    instruments = defaultdict(int) # default to code 0 = piano\n",
    "    tempo = 500000 # default tempo: 500000 microseconds per beat\n",
    "    for message in midi:\n",
    "        time += message.time\n",
    "\n",
    "        # sanity check: negative time?\n",
    "        if message.time < 0:\n",
    "            raise ValueError\n",
    "\n",
    "        if message.type == 'program_change':\n",
    "            instruments[message.channel] = message.program\n",
    "        elif message.type in ['note_on', 'note_off']:\n",
    "            # special case: channel 9 is drums!\n",
    "            instr = 128 if message.channel == 9 else instruments[message.channel]\n",
    "\n",
    "            if message.type == 'note_on' and message.velocity > 0: # onset\n",
    "                # time quantization\n",
    "                time_in_ticks = round(TIME_RESOLUTION*time)\n",
    "\n",
    "                # Our compound word is: (time, duration, note, instr, velocity)\n",
    "                tokens.append(time_in_ticks) # 5ms resolution\n",
    "                tokens.append(-1) # placeholder (we'll fill this in later)\n",
    "                tokens.append(message.note)\n",
    "                tokens.append(instr)\n",
    "                tokens.append(message.velocity)\n",
    "\n",
    "                open_notes[(instr,message.note,message.channel)].append((note_idx, time))\n",
    "                note_idx += 1\n",
    "            else: # offset\n",
    "                try:\n",
    "                    open_idx, onset_time = open_notes[(instr,message.note,message.channel)].pop(0)\n",
    "                except IndexError:\n",
    "                    if debug:\n",
    "                        print('WARNING: ignoring bad offset')\n",
    "                else:\n",
    "                    duration_ticks = round(TIME_RESOLUTION*(time-onset_time))\n",
    "                    tokens[5*open_idx + 1] = duration_ticks\n",
    "                    # if duration_ticks == 36: duration_ticks = 18\n",
    "\n",
    "                    # print(\"onset_time\", onset_time, \"duration_ticks\", duration_ticks)\n",
    "                    onset_time_in_ticks = round(TIME_RESOLUTION*onset_time)\n",
    "\n",
    "                    closed_notes[(instr,message.note,message.channel, onset_time_in_ticks, duration_ticks)] = track_num\n",
    "\n",
    "                    #del open_notes[(instr,message.note,message.channel)]\n",
    "        elif message.type == 'set_tempo':\n",
    "            tempo = message.tempo\n",
    "        elif message.type == 'time_signature':\n",
    "            # print('TIME SIGNATURE', message)\n",
    "            pass # we use real time\n",
    "        elif message.type in ['aftertouch', 'polytouch', 'pitchwheel', 'sequencer_specific']:\n",
    "            pass # we don't attempt to model these\n",
    "        elif message.type == 'control_change':\n",
    "            pass # this includes pedal and per-track volume: ignore for now\n",
    "        elif message.type in ['track_name', 'text', 'end_of_track', 'lyrics', 'key_signature',\n",
    "                            'copyright', 'marker', 'instrument_name', 'cue_marker',\n",
    "                            'device_name', 'sequence_number']:\n",
    "            pass # possibly useful metadata but ignore for now\n",
    "        elif message.type == 'channel_prefix':\n",
    "            pass # relatively common, but can we ignore this?\n",
    "        elif message.type in ['midi_port', 'smpte_offset', 'sysex']:\n",
    "            pass # I have no idea what this is\n",
    "        else:\n",
    "            if debug:\n",
    "                print('UNHANDLED MESSAGE', message.type, message)\n",
    "\n",
    "    unclosed_count = 0\n",
    "    for _,v in open_notes.items():\n",
    "        unclosed_count += len(v)\n",
    "\n",
    "    if debug and unclosed_count > 0:\n",
    "        print(f'WARNING: {unclosed_count} unclosed notes')\n",
    "        print('  ', track_midifile)\n",
    "\n",
    "    return closed_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0678c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_to_events_and_notes(tokens, stats=False):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - tokens: list of tokens in the pattern (start time, duration, MIDI note, instrument, velocity, channel)\n",
    "            - should be multiple of 6\n",
    "\n",
    "    returns:\n",
    "        - events: tokens for input to model (start_time, duration_token, note_token)\n",
    "            - removes velocity and channel\n",
    "            - duration_token capped at MAX_DUR, if unknown set to 250ms\n",
    "            - note_token = NOTE_OFFSET + (MAX_PITCH*instr + note)\n",
    "        - notes: list of Note objects\n",
    "            - sets pitch, instrument, start time, duration, dict_key\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(tokens) % 6 == 0\n",
    "    tokens = tokens.copy()\n",
    "\n",
    "    # remove velocities\n",
    "    del tokens[4::6]\n",
    "\n",
    "    # combine (note, instrument)\n",
    "    assert all(-1 <= tok < 2**7 for tok in tokens[2::5]) # check that values valid\n",
    "    assert all(-1 <= tok < 129 for tok in tokens[3::5]) # check that values valid\n",
    "\n",
    "    notes = []\n",
    "\n",
    "    for start, dur, note, instr, channel in zip(tokens[0::5], tokens[1::5], tokens[2::5], tokens[3::5], tokens[4::5]):\n",
    "        if note == -1:\n",
    "            notes.append(SEPARATOR)\n",
    "        else:\n",
    "            cur_duration = TIME_RESOLUTION//4 if dur == -1 else min(dur, MAX_DUR-1)\n",
    "            # don't readjust duration by dur_offset (not necessary?)\n",
    "            # (instr,message.note, message.channel, onset_time, duration_ticks)\n",
    "            dict_key = (instr, note, channel, start, dur)\n",
    "            cur_note = Note(pitch=note, instrument=instr, start=start, duration=cur_duration, dict_key=dict_key)\n",
    "            notes.append(cur_note)\n",
    "    \n",
    "    del tokens[4::5]\n",
    "\n",
    "    # set to separator if note is -1\n",
    "    # otherwise set the note to MAX_PITCH*instr + note\n",
    "    tokens[2::4] = [SEPARATOR if note == -1 else MAX_PITCH*instr + note\n",
    "                    for note, instr in zip(tokens[2::4],tokens[3::4])]\n",
    "    tokens[2::4] = [NOTE_OFFSET + tok for tok in tokens[2::4]]\n",
    "    del tokens[3::4]\n",
    "\n",
    "    # max duration cutoff and set unknown durations to 250ms\n",
    "    truncations = sum([1 for tok in tokens[1::3] if tok >= MAX_DUR])\n",
    "    tokens[1::3] = [TIME_RESOLUTION//4 if tok == -1 else min(tok, MAX_DUR-1)\n",
    "                    for tok in tokens[1::3]]\n",
    "    tokens[1::3] = [DUR_OFFSET + tok for tok in tokens[1::3]]\n",
    "\n",
    "    assert min(tokens[0::3]) >= 0\n",
    "    tokens[0::3] = [TIME_OFFSET + tok for tok in tokens[0::3]]\n",
    "\n",
    "    assert len(tokens) % 3 == 0\n",
    "\n",
    "    if stats:\n",
    "        return tokens, truncations\n",
    "\n",
    "    return tokens, notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7433405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_note_track_number(notes, note_track_dict):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - notes: list of Note objects\n",
    "        - note_track_dict: dictionary with\n",
    "            - key = (instrument, note, channel, onset_time_in_ticks, duration_ticks)\n",
    "            - value = track number\n",
    "\n",
    "    sets the track number for each Note object in notes\n",
    "    \"\"\"\n",
    "    for note in notes:\n",
    "        key = note.get_dict_key()\n",
    "        if key in note_track_dict:\n",
    "            note.set_track_number(note_track_dict[key])\n",
    "        else:\n",
    "            print(\"ERROR: key not found in note_track_dict:\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3914cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_notes(notes):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - notes: list of Note objects (MUST have track_number field set)\n",
    "    \n",
    "    since notes are in order, it should add them to each dictionary entry list in time order\n",
    "\n",
    "    returns a dictionary with:\n",
    "        - key = track number\n",
    "        - value = list of Note objects in that track\n",
    "    \"\"\"\n",
    "    track_notes = defaultdict(list)\n",
    "\n",
    "    for note in notes:\n",
    "        track_num = note.get_track_number()\n",
    "        if track_num is None:\n",
    "            print(\"ERROR: note does not have track number set:\", note)\n",
    "        else:\n",
    "            track_notes[note.get_track_number()].append(note)\n",
    "\n",
    "    return track_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b4e1b",
   "metadata": {},
   "source": [
    "# Pre-Processing Code\n",
    "\n",
    "`midi_to_compound(midifile)`\n",
    "- input a MIDI file with **all** tracks\n",
    "- outputs tokens (to turn into events) and a list of keys for all notes\n",
    "\n",
    "`midi_tracks_to_dict(midifile, track_num)`\n",
    "- input a MIDI file with a **single** track\n",
    "- outputs a dictionary of keys corresponding to note in track, value = track number\n",
    "\n",
    "`compound_to_events_and_notes(tokens)`\n",
    "- input the tokens from `midi_to_compound`\n",
    "- outputs events (the actual tokens for model) and a list of Note objects corresponding to each note (in same order)\n",
    "\n",
    "`set_note_track_number(notes, note_track_dict)`\n",
    "- input the list of Note objects from `compound_to_events_and_notes` and dictionary matching note to track number from `midi_tracks_to_dict`\n",
    "- modifies each Note object to store the correct track number\n",
    "- does not output anything\n",
    "\n",
    "`get_track_notes(notes)`\n",
    "- input a list of Note objects AFTER calling `set_note_track_number`\n",
    "- outputs a dictionary with key as track number and value as list of Note objects in that track\n",
    "\n",
    "### To process a MIDI file:\n",
    "1. pass MIDI with **all tracks** into `isolate_midi_tracks(midifile)`. this splits up the file into separate tracks (for tagging later)\n",
    "2. pass MIDI with **all tracks** into `midi_to_compound(midifile)` to get tokenized rep `(start time, duration, MIDI note, instrument, velocity, channel)`, as well as a list of dictionary key reps for all the notes\n",
    "3. take tokens from `midi_to_compound(midifile)` output and put into `compound_to_events_and_notes(tokens)` to get events (model input) and list of Note objects corresponding to the parsed notes\n",
    "4. pass MIDI for **each track** into `midi_tracks_to_dict(midifile, track_num)` with respective track number to get a dictionary with key=note key and val=track number. combine all dictionary outputs so we have a big dictionary mapping all note keys to respective track number\n",
    "5. pass in list of Note objects from `midi_to_compound(midifile)` and combined dictionary from step 4 into `set_note_track_number(notes, note_track_dict)` to set the correct track number field for each Note object.\n",
    "6. pass in list of Notes **after setting track numbers** into `get_track_notes(notes)` to get a dictionary mapping each track number to a list of Note objects in that track (for more efficient acccess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d730d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_midi_file(midifile, track_midifiles):\n",
    "    \"\"\"\n",
    "    processes a given MIDI file by creating Note objects corresponding to the MIDI notes, as well as labelling Notes by track\n",
    "    parameters: \n",
    "        - midifile: MIDI file path with all tracks\n",
    "        - track_midifiles: list of MIDI file paths for each track\n",
    "\n",
    "    returns:\n",
    "        - all_note_keys: list of all the keys of notes (instrument, note, channel, onset_time_in_ticks, duration_ticks) in MIDI order\n",
    "        - notes: list of all Note objects in the model token order\n",
    "        - notes_per_track: dictionary with key = track number, value = list of Note objects in that track (in notes)\n",
    "    \"\"\"\n",
    "    midi = mido.MidiFile(midifile)\n",
    "    \n",
    "    # tokens = to be input into compound_to_events_and_notes\n",
    "    # all_note_keys = list of keys of notes (instrument, note, channel, onset_time_in_ticks, duration_ticks)\n",
    "    tokens, all_note_keys = midi_to_compound(midi)\n",
    "\n",
    "    # events = tokens for model input\n",
    "    # notes = list of Note objects\n",
    "    events, notes = compound_to_events_and_notes(tokens)\n",
    "\n",
    "\n",
    "    # store track number for every note key\n",
    "    note_track_dict = {}\n",
    "    for i, track_midifile in enumerate(track_midifiles):\n",
    "        track_note_dict = midi_tracks_to_dict(track_midifile, i)\n",
    "        # combine into larger dictionary mapping notes to track number\n",
    "        note_track_dict.update(track_note_dict)\n",
    "        \n",
    "    # DEBUGGING CODE\n",
    "    # keys_from_tracks = list(note_track_dict.keys())\n",
    "    # sorted_all_note_keys = sorted(all_note_keys)\n",
    "    # sorted_keys_from_tracks = sorted(keys_from_tracks)\n",
    "    # print(\"all note keys sorted\", sorted_all_note_keys)\n",
    "    # print(\"all track note keys sorted\", sorted_keys_from_tracks)\n",
    "    # print(len(all_note_keys),len(keys_from_tracks))\n",
    "    \n",
    "    # set the track number field for each Note object\n",
    "    set_note_track_number(notes, note_track_dict)\n",
    "\n",
    "    # get dictionary mapping track number to the list of Note objects in that track\n",
    "    notes_per_track = get_track_notes(notes)\n",
    "\n",
    "    return all_note_keys, notes, notes_per_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4be609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_midi_tracks(midifile):\n",
    "    \"\"\"\n",
    "    given a MIDI file with multiple tracks, saves each track into a separate MIDI file (preserving tempo, etc.)\n",
    "    parameters: \n",
    "        - midifile: MIDI file path with all tracks\n",
    "\n",
    "    returns:\n",
    "        - all_track_midis: list of all track MIDI file paths\n",
    "    \"\"\"\n",
    "    midi = mido.MidiFile(midifile)\n",
    "\n",
    "    all_track_midis = []\n",
    "    prefix = midifile[:midifile.index(\".mid\")]\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    count = 0\n",
    "    for msg in midi.tracks[0]:\n",
    "        # if msg.is_meta:\n",
    "        #     metadata.append(msg.copy())\n",
    "        if msg.type in ['time_signature', 'key_signature', 'set_tempo']:\n",
    "            metadata.append(msg.copy())\n",
    "        count += 1\n",
    "        if count > 10: break\n",
    "    \n",
    "    new_mid = mido.MidiFile()\n",
    "\n",
    "    for i, track in enumerate(midi.tracks):\n",
    "\n",
    "        new_mid = mido.MidiFile()\n",
    "        # set ticks per beat to be the same\n",
    "        new_mid.ticks_per_beat = midi.ticks_per_beat\n",
    "        new_mid.tracks.append(metadata.copy())\n",
    "        new_mid.tracks[0] += track\n",
    "\n",
    "        filename = f'{prefix}_track{i}.mid'\n",
    "\n",
    "        all_track_midis.append(filename)\n",
    "        new_mid.save(filename)\n",
    "    \n",
    "    return all_track_midis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f54035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_from_midi(midifile):\n",
    "    \"\"\"\n",
    "    FOR DEBUGGING: iterate through entire MIDI and store all info in CSV file\n",
    "    parameters: \n",
    "        - midifile: input MIDI file path\n",
    "    \n",
    "    saves MIDI file as a CSV with columns \"start\", \"start_ticks\", \"end\", \"duration_ticks\", \"instr\", \"note\", \"channel\", \"key\", \"final_key\"\n",
    "\n",
    "    returns:\n",
    "        - nothing\n",
    "    \"\"\"\n",
    "\n",
    "    if type(midifile) == str:\n",
    "        midi = mido.MidiFile(midifile)\n",
    "    else:\n",
    "        midi = midifile\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"start\", \"start_ticks\", \"end\", \"duration_ticks\", \"instr\", \"note\", \"channel\", \"key\", \"final_key\"])\n",
    "    print(df)\n",
    "\n",
    "    tokens = []\n",
    "    note_idx = 0\n",
    "    open_notes = defaultdict(list)\n",
    "    closed_notes = []\n",
    "\n",
    "    time = 0\n",
    "    instruments = defaultdict(int) # default to code 0 = piano\n",
    "    tempo = 500000 # default tempo: 500000 microseconds per beat\n",
    "\n",
    "    for message in midi:\n",
    "        time += message.time\n",
    "        # print(\"MESSAGE\", message, round(TIME_RESOLUTION*time))\n",
    "\n",
    "        # sanity check: negative time?\n",
    "        if message.time < 0:\n",
    "            raise ValueError\n",
    "\n",
    "        if message.type == 'program_change':\n",
    "            instruments[message.channel] = message.program\n",
    "        elif message.type in ['note_on', 'note_off']:\n",
    "            # special case: channel 9 is drums!\n",
    "            instr = 128 if message.channel == 9 else instruments[message.channel]\n",
    "\n",
    "            if message.type == 'note_on' and message.velocity > 0: # onset\n",
    "                # time quantization\n",
    "                time_in_ticks = round(TIME_RESOLUTION*time)\n",
    "\n",
    "                # Our compound word is: (time, duration, note, instr, velocity)\n",
    "                tokens.append(time_in_ticks) # 5ms resolution\n",
    "                tokens.append(-1) # placeholder (we'll fill this in later)\n",
    "                tokens.append(message.note)\n",
    "                tokens.append(instr)\n",
    "                tokens.append(message.velocity)\n",
    "\n",
    "                tokens.append(message.channel) # CHANNEL INFO FOR KEY\n",
    "\n",
    "                key = (instr,message.note,message.channel)\n",
    "                open_notes[key].append((note_idx, time))\n",
    "                print(note_idx)\n",
    "                print([time, time_in_ticks, -1, -1, instr, message.note, message.channel, key, -1])\n",
    "                df.loc[note_idx] = [time, time_in_ticks, -1.0, -1, instr, message.note, message.channel, key, \"-1\"]\n",
    "\n",
    "                note_idx += 1\n",
    "\n",
    "            else: # offset\n",
    "                try:\n",
    "                    open_idx, onset_time = open_notes[(instr,message.note,message.channel)].pop(0)\n",
    "                except IndexError:\n",
    "                    if debug:\n",
    "                        print('WARNING: ignoring bad offset')\n",
    "                else:\n",
    "                    duration_ticks = round(TIME_RESOLUTION*(time-onset_time))\n",
    "                    # tokens[5*open_idx + 1] = duration_ticks\n",
    "                    tokens[6*open_idx + 1] = duration_ticks # ACCOUNT FOR CHANNEL\n",
    "                    # print(\"onset time:\", onset_time, \"duration_ticks:\", duration_ticks)\n",
    "                    onset_time_in_ticks = round(TIME_RESOLUTION*onset_time)\n",
    "\n",
    "                    closed_notes.append((instr,message.note, message.channel, onset_time_in_ticks, duration_ticks))\n",
    "                    # print(type(time))\n",
    "                    df.loc[open_idx, \"end\"] = time\n",
    "                    df.loc[open_idx, \"duration_ticks\"] = duration_ticks\n",
    "                    df.loc[open_idx, \"final_key\"] = str((instr,message.note, message.channel, onset_time_in_ticks, duration_ticks))\n",
    "\n",
    "        elif message.type == 'set_tempo':\n",
    "            tempo = message.tempo\n",
    "        elif message.type == 'time_signature':\n",
    "            # print('TIME SIGNATURE', message)\n",
    "            pass # we use real time\n",
    "        elif message.type in ['aftertouch', 'polytouch', 'pitchwheel', 'sequencer_specific']:\n",
    "            pass # we don't attempt to model these\n",
    "        elif message.type == 'control_change':\n",
    "            pass # this includes pedal and per-track volume: ignore for now\n",
    "        elif message.type in ['track_name', 'text', 'end_of_track', 'lyrics', 'key_signature',\n",
    "                              'copyright', 'marker', 'instrument_name', 'cue_marker',\n",
    "                              'device_name', 'sequence_number']:\n",
    "            pass # possibly useful metadata but ignore for now\n",
    "        elif message.type == 'channel_prefix':\n",
    "            pass # relatively common, but can we ignore this?\n",
    "        elif message.type in ['midi_port', 'smpte_offset', 'sysex']:\n",
    "            pass # I have no idea what this is\n",
    "        else:\n",
    "            if debug:\n",
    "                print('UNHANDLED MESSAGE', message.type, message)\n",
    "        # print(tokens)\n",
    "\n",
    "    # print(df)\n",
    "    df.to_csv(midifile[:midifile.index(\".mid\")]+\"_notes.csv\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfed26",
   "metadata": {},
   "source": [
    "# Labeling Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9251022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_notes_by_index_range(notes, start, end, func):\n",
    "    \"\"\"\n",
    "    modifies the notes to do [func] in an index range (inclusive)\n",
    "    parameters:\n",
    "        - notes: list of all Note objects\n",
    "        - start: starting index (inclusive)\n",
    "        - end: ending index (inclusive)\n",
    "        - func: function corresponding to Note class function\n",
    "    \"\"\"\n",
    "    for i in range(start, end+1):\n",
    "        func(notes[i])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd13fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_notes_by_time_range(notes, start, end, func, in_ticks=False):\n",
    "    \"\"\"\n",
    "    modifies the notes within a time range\n",
    "    time in the Notes is stored by a converted time_in_ticks (time_in_ticks = round(TIME_RESOLUTION*time))\n",
    "    set in_ticks to be true if start, end are in ticks, else will convert the Note time to seconds\n",
    "    parameters:\n",
    "        - notes: list of all Note objects\n",
    "        - start: starting time (inclusive), in seconds if in_ticks=False else in ticks\n",
    "        - end: ending time (inclusive), in seconds if in_ticks=False else in ticks\n",
    "        - func: function corresponding to Note class function\n",
    "        - in_ticks: whether or not start, end are in ticks. default is False (start, end in seconds)\n",
    "    \"\"\"\n",
    "    # if start, end in seconds, then convert start, end to ticks\n",
    "    if not in_ticks:\n",
    "        start = round(TIME_RESOLUTION*start)\n",
    "        end = round(TIME_RESOLUTION*end)\n",
    "    \n",
    "    for note in notes:\n",
    "        note_start = note.get_start_time()\n",
    "        if note_start >= start and note_start <= end:\n",
    "            func(note)\n",
    "        elif note_start > end:\n",
    "            break\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ed7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_notes_by_track(notes_per_track, track_num, func):\n",
    "    \"\"\"\n",
    "    modifies all notes in a track to do some [func]\n",
    "    parameters:\n",
    "        - notes_per_track: dictionary mapping track number to a list of Note objects in that track\n",
    "        - track_num: the track we want to modify\n",
    "        - func: function corresponding to Note class function\n",
    "    \"\"\"\n",
    "    notes = notes_per_track[track_num]\n",
    "    for note in notes:\n",
    "        func(note)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a32871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_notes_in_list(note_list, func):\n",
    "    \"\"\"\n",
    "    modifies all notes in a given list to do some [func]\n",
    "    parameters:\n",
    "        - note_list: list of Note objects\n",
    "        - func: function corresponding to Note class function\n",
    "    \"\"\"\n",
    "    for note in note_list:\n",
    "        func(note)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99653a66",
   "metadata": {},
   "source": [
    "# Labeling Code w/ MIDI Input\n",
    "\n",
    "list of modification functions in Note class:\n",
    "- `add_tag(tag: str)`: tag is unspecified string (manually set), ex: motif, repetition, rigid/rubato\n",
    "- `set_key_and_interval(key)`: key is MIDI note number, sets key=key, interval=(pitch-key) % 12\n",
    "- `set_melody(is_melody)`: is_melody is boolean\n",
    "- `set_chord(is_chord)`: is_chord is boolean\n",
    "\n",
    "use these modification functions in the `func` param for the labeling code above\n",
    "- ex: `func = lambda x: x.set_key_and_interval(60)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee2e1c",
   "metadata": {},
   "source": [
    "# Analysis Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777a426",
   "metadata": {},
   "source": [
    "### Load Attention Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d171c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attn_matrices(filename, filepath_prefix):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        - filename: midi file name\n",
    "        - filepath_prefix: path prefix to the attention matrix file\n",
    "\n",
    "    returns:\n",
    "        - attention_matrices = list of pandas dataframes corresponding to each attention matrix\n",
    "    \"\"\"\n",
    "\n",
    "    filename = filename[:filename.index(\".mid\")] if \".mid\" in filename else filename\n",
    "\n",
    "    attention_heads = []\n",
    "    for i in range(0, 12):\n",
    "        cur_filename = f'{filename}_head{i}.npy'\n",
    "        cur_filepath = f'{filepath_prefix}/{cur_filename}'\n",
    "        cur_matrix = np.load(cur_filepath)\n",
    "\n",
    "        matrix_df = pd.DataFrame(cur_matrix)\n",
    "        matrix_df = matrix_df.iloc[1:, 1:] # remove first row+col (corresponds to CLS token)\n",
    "        attention_heads.append(matrix_df)\n",
    "    return attention_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81a950",
   "metadata": {},
   "source": [
    "### Create Rescaled Attention Matrices\n",
    "\n",
    "1. **rescale wrt uniform attention**: each entry in the attention matrices = `attn_val / (1/(# tokens attended to so far))`, which basically corresponds to uniform attention in a row. since the attention matrices are diagonal, this helps maintain a more consistent value across different rows where the model is paying attention to different numbers of tokens.\n",
    "2. **compute Z score of attention row**: each entry in the attention matrices = `# std deviations away from the avg attention of that row`. this does a similar thing but now we are able to assess average attentions. \n",
    "\n",
    "**NOTE:** can also maybe calculate the distribution/std dev of attentions per row? this might tell us if an attention head is very focused on specific notes vs focused on a lot of notes at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5aa2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_attn_matrix_unif(attention_matrices):\n",
    "    \"\"\"\n",
    "    create rescaled matrices wrt uniform attention\n",
    "    each entry is (attn value) / (1/(num tokens attended to so far))\n",
    "    which corresponds to uniform attention in that row\n",
    "    \n",
    "    parameters:\n",
    "        - attention_matrices: list of pandas dataframes corresponding to each attention matrix\n",
    "\n",
    "    returns:\n",
    "        - rescaled_attention_matrices: list of pandas dataframes corresponding to each rescaled attention matrix\n",
    "    \"\"\"\n",
    "    rescaled_attention_matrices = []\n",
    "\n",
    "    for attn_matrix in attention_matrices:\n",
    "        rescaled_matrix = attn_matrix.copy()\n",
    "\n",
    "        for i in range(rescaled_matrix.shape[0]):\n",
    "            unif_value = 1 / (i+1)\n",
    "            rescaled_matrix.iloc[i,:] = rescaled_matrix.iloc[i,:] / unif_value\n",
    "        rescaled_attention_matrices.append(rescaled_matrix)\n",
    "    \n",
    "    return rescaled_attention_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5259e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_attn_matrix_zscore(attention_matrices):\n",
    "    \"\"\"\n",
    "    create Z-score matrices (per row)\n",
    "    each entry is how much attention is given to a token wrt mean attention for that row\n",
    "    ex: token 2 attends to token 1 with attention that is 2 std above mean attention for that row \n",
    "    NOTE: upper right triangle left as 0\n",
    "\n",
    "    parameters:\n",
    "        - attention_matrices: list of pandas dataframes corresponding to each attention matrix\n",
    "\n",
    "    returns:\n",
    "        - zscore_attention_matrices: list of pandas dataframes corresponding to each Z-score attention matrix\n",
    "    \"\"\"\n",
    "    zscore_attn_matrices = []\n",
    "    attn_matrices_stats = []\n",
    "\n",
    "    for attn_head in attention_matrices:\n",
    "        copy_attn_head = attn_head.copy()\n",
    "        stats_df = pd.DataFrame(index=range(attn_head.shape[0]), columns=['mean', 'std'])\n",
    "\n",
    "        for i in range(attn_head.shape[0]):\n",
    "            # get mean and std dev for that row (up to col i+1 bc only for tokens attended to so far)\n",
    "            row_mean = attn_head.iloc[i,:i+1].mean()\n",
    "            row_std = attn_head.iloc[i,:i+1].std()\n",
    "\n",
    "            # if row_std = 0 or nan\n",
    "            if row_std == 0 or np.isnan(row_std):\n",
    "                # if all attention values are the same, set to 0\n",
    "                copy_attn_head.iloc[i,:] = 0\n",
    "            else:\n",
    "                # calculate z-score\n",
    "                copy_attn_head.iloc[i,:i+1] = (copy_attn_head.iloc[i,:i+1] - row_mean) / row_std\n",
    "\n",
    "            # populate mean and std dev dataframe\n",
    "            stats_df.loc[i, 'mean'] = row_mean\n",
    "            stats_df.loc[i, 'std'] = row_std\n",
    "\n",
    "        zscore_attn_matrices.append(copy_attn_head)\n",
    "        attn_matrices_stats.append(stats_df)\n",
    "\n",
    "    return zscore_attn_matrices, attn_matrices_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41fce9",
   "metadata": {},
   "source": [
    "### Top K Most Attended to Tokens per Attention Head\n",
    "\n",
    "this is done by:\n",
    "1. taking rescaled attention matrix (z-score)\n",
    "2. averaging the z-score for every single token (theoretically should not be skewed by order / # tokens attended to)\n",
    "3. return top K highest average tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561d8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_zscore_tokens(zscore_attn_matrices, k, num_input_tokens):\n",
    "    \"\"\"\n",
    "    for each attention matrix, get the top k tokens with highest z-score attention for each row\n",
    "\n",
    "    parameters:\n",
    "        - zscore_attn_matrices: list of pandas dataframes corresponding to each Z-score attention matrix\n",
    "        - k: top k tokens to get\n",
    "    returns:\n",
    "        - top_k_tokens_per_matrix: list of lists of lists\n",
    "            - outer list: per attention matrix\n",
    "            - middle list: per row\n",
    "            - inner list: top k token indices with highest z-score attention\n",
    "\n",
    "    \"\"\"\n",
    "    top_k_tokens_per_matrix = []\n",
    "    # num_tokens = len(zscore_attn_matrices[0])\n",
    "\n",
    "    for matrix in zscore_attn_matrices:\n",
    "        cur_matrix_index_sums = []\n",
    "        # sum up each matrix column\n",
    "        for i in range(matrix.shape[1]):\n",
    "            # don't consider generated tokens\n",
    "            if i >= num_input_tokens: break\n",
    "            \n",
    "            # # sum up starting at row i to ignore upper triangle\n",
    "            # col_sum = matrix.iloc[i:,i].sum()\n",
    "            # # get average (divide by # times the token is attended to)\n",
    "            # col_avg = col_sum / matrix.iloc[i:,i].shape[0]\n",
    "\n",
    "            # col_med = matrix.iloc[i:,i].median()\n",
    "            col_avg = matrix.iloc[i:,i].mean()\n",
    "\n",
    "            cur_matrix_index_sums.append((i, col_avg.item()))\n",
    "            # cur_matrix_index_sums.append((i, col_med.item()))\n",
    "\n",
    "        # sort by column average\n",
    "        cur_matrix_index_sums = sorted(cur_matrix_index_sums, key=lambda x: x[1])\n",
    "\n",
    "        top_k_tokens_per_matrix.append(cur_matrix_index_sums[-k:]) # get top k tokens\n",
    "    return top_k_tokens_per_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d67b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_stats_input(top_k_per_head, notes):\n",
    "    \"\"\"\n",
    "    given a list of lists (the top k token indices for all attention heads), \n",
    "    return the corresponding Note objects and token indices for these tokens\n",
    "    this is 1:1 to the input to get_note_states(notes, indices)\n",
    "    \"\"\"\n",
    "    all_attn_head_notes = []\n",
    "    all_attn_head_token_indexes = []\n",
    "    for head_num in range(len(top_k_per_head)):\n",
    "        head_notes = []\n",
    "        head_token_indexes = []\n",
    "\n",
    "        # for the top k tokens for a head\n",
    "        for item in top_k_per_head[head_num]:\n",
    "            index, score = item\n",
    "            note_index = math.floor(index/3)\n",
    "\n",
    "            # get the corresponding Note object and token index\n",
    "            head_notes.append(notes[note_index])\n",
    "            head_token_indexes.append(index)\n",
    "\n",
    "        # append to final lists\n",
    "        all_attn_head_notes.append(head_notes)\n",
    "        all_attn_head_token_indexes.append(head_token_indexes)\n",
    "\n",
    "    return all_attn_head_notes, all_attn_head_token_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db3c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_stats(notes, indices):\n",
    "    \"\"\"\n",
    "    TODO: THIS IS SUPER BASIC STAT INFO, CAN ADD EXTENSIONS THAT LOOK AT CORRELATIONS BETWEEN FIELDS\n",
    "    ex: are all notes w X tag also longer than Y duration?\n",
    "\n",
    "    parameters:\n",
    "        - notes: list of Note objects (combined from different files)\n",
    "        - indices: list of indices corresponding to the notes (%3 for type of token: 0=start time, 1=duration, 2=note)\n",
    "    returns:\n",
    "        - stats: dictionary with statistics about the notes (e.g., pitch distribution, instrument distribution, duration stats)\n",
    "    \"\"\"\n",
    "    total_notes = len(notes)\n",
    "    # get number of each token type\n",
    "    num_start = 0\n",
    "    num_duration = 0\n",
    "    num_note = 0\n",
    "    for i in indices:\n",
    "        token_type = i % 3\n",
    "        if token_type == 0:\n",
    "            num_start += 1\n",
    "        elif token_type == 1:\n",
    "            num_duration += 1\n",
    "        elif token_type == 2:\n",
    "            num_note += 1\n",
    "        \n",
    "    durations = []\n",
    "    pitches = defaultdict(int)\n",
    "    intervals = defaultdict(int)\n",
    "    tags = defaultdict(int)\n",
    "    keys = defaultdict(int)\n",
    "\n",
    "    # compile all info\n",
    "    for note in notes:\n",
    "        pitches[note.pitch] += 1\n",
    "        durations.append(note.duration)\n",
    "        if note.key is not None:\n",
    "            intervals[note.interval] += 1\n",
    "            keys[note.key] += 1\n",
    "        # increment tag counts\n",
    "        for tag in note.tags:\n",
    "            tags[tag] += 1\n",
    "\n",
    "\n",
    "    # get actual summary statistics\n",
    "    summary = {}\n",
    "    summary['total_num_notes'] = total_notes\n",
    "\n",
    "    # token type\n",
    "    summary['num_start_tokens'] = num_start\n",
    "    summary['num_duration_tokens'] = num_duration\n",
    "    summary['num_note_tokens'] = num_note\n",
    "\n",
    "    # duration stats\n",
    "    summary['avg_duration'] = np.mean(durations)\n",
    "    summary['std_duration'] = np.std(durations)\n",
    "    summary['median_duration'] = np.median(durations)\n",
    "    summary['min_duration'] = np.min(durations)\n",
    "    summary['max_duration'] = np.max(durations)\n",
    "\n",
    "    # pitch stats\n",
    "    for key in pitches.keys():\n",
    "        summary[f'pitch_{key}_count'] = pitches[key]\n",
    "    \n",
    "    # interval stats\n",
    "    for key in intervals.keys():\n",
    "        summary[f'interval_{key}_count'] = intervals[key]\n",
    "    for key in keys.keys():\n",
    "        summary[f'key_{key}_count'] = keys[key]\n",
    "    \n",
    "    # tag stats\n",
    "    for key in tags.keys():\n",
    "        summary[f'tag_{key}_count'] = tags[key]\n",
    "\n",
    "    summary_df = pd.DataFrame([summary])\n",
    "    \n",
    "    return(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b0426",
   "metadata": {},
   "source": [
    "# repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11950c5",
   "metadata": {},
   "source": [
    "## repetition1.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88855aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "repetition1_midis = isolate_midi_tracks(\"repetition1/repetition1.mid\")\n",
    "\n",
    "repetition1_all_note_keys, repetition1_notes, repetition1_notes_per_track = process_midi_file(\"repetition1/repetition1.mid\", repetition1_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(repetition1_notes, 0, len(repetition1_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# TAG NOTES\n",
    "# first 2 bars are motif0 repeat 1\n",
    "modify_notes_by_time_range(repetition1_notes, 0, 5.714288000000003, lambda x: x.add_tag(\"repetition1_motif0_0\"), in_ticks=False)\n",
    "\n",
    "# last 2 bars are motif0 repeat 2\n",
    "modify_notes_by_time_range(repetition1_notes, 5.714288000000003, 11.428576000000006, lambda x: x.add_tag(\"repetition1_motif0_1\"), in_ticks=False)\n",
    "\n",
    "# track 0 is melody\n",
    "modify_notes_by_track(repetition1_notes_per_track, 0, lambda x: x.add_tag(\"repetition1_melody\"))\n",
    "\n",
    "# track 2 + track 3 as repetitive + accompaniment\n",
    "modify_notes_by_track(repetition1_notes_per_track, 2, lambda x: x.add_tag(\"repetition1_repetitive_notes\"))\n",
    "modify_notes_by_track(repetition1_notes_per_track, 2, lambda x: x.add_tag(\"repetition1_accompaniment\"))\n",
    "\n",
    "modify_notes_by_track(repetition1_notes_per_track, 3, lambda x: x.add_tag(\"repetition1_repetitive_notes\"))\n",
    "modify_notes_by_track(repetition1_notes_per_track, 3, lambda x: x.add_tag(\"repetition1_accompaniment\"))\n",
    "\n",
    "# for note in notes:\n",
    "#     print(note.pitch)\n",
    "#     print(note.start)\n",
    "#     print(note.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9092a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "repetition1_attn_matrices = load_attn_matrices(\"repetition1.mid\", \"repetition1/repetition1_heads\")\n",
    "repetition1_unif_attn_matrices = rescale_attn_matrix_unif(repetition1_attn_matrices)\n",
    "repetition1_zscore_attn_matrices, repetition1_attn_stats = rescale_attn_matrix_zscore(repetition1_attn_matrices)\n",
    "# print(repetition1_attn_stats[0].head)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# repetition1_topks = get_top_k_zscore_tokens(repetition1_zscore_attn_matrices, k=10, num_input_tokens=3*len(repetition1_notes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4b23e",
   "metadata": {},
   "source": [
    "## repetition2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "repetition2_midis = isolate_midi_tracks(\"repetition2/repetition2.mid\")\n",
    "\n",
    "repetition2_all_note_keys, repetition2_notes, repetition2_notes_per_track = process_midi_file(\"repetition2/repetition2.mid\", repetition2_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(repetition2_notes, 0, len(repetition2_notes)-1, lambda x: x.set_key_and_interval(61))\n",
    "\n",
    "# set motif repeat every bar\n",
    "modify_notes_by_time_range(repetition2_notes, 0, 1.4008333333333332, lambda x: x.add_tag(\"motif0_0\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 1.6008333333333332, 3.000833333333333, lambda x: x.add_tag(\"repetition2_motif0_1\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 3.200833333333333, 4.600833333333334, lambda x: x.add_tag(\"repetition2_motif0_2\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 4.800833333333334, 6.200833333333335, lambda x: x.add_tag(\"repetition2_motif0_3\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 6.400833333333336, 7.800833333333337, lambda x: x.add_tag(\"repetition2_motif0_4\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 8.000833333333336, 9.400833333333331, lambda x: x.add_tag(\"repetition2_motif0_5\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 9.60083333333333, 11.000833333333325, lambda x: x.add_tag(\"repetition2_motif0_6\"), in_ticks=False)\n",
    "modify_notes_by_time_range(repetition2_notes, 11.200833333333325, 12.800833333333319, lambda x: x.add_tag(\"repetition2_motif0_7\"), in_ticks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "repetition2_attn_matrices = load_attn_matrices(\"repetition2.mid\", \"repetition2/repetition2_heads\")\n",
    "repetition2_unif_attn_matrices = rescale_attn_matrix_unif(repetition2_attn_matrices)\n",
    "repetition2_zscore_attn_matrices, repetition2_attn_stats = rescale_attn_matrix_zscore(repetition2_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# repetition2_topks = get_top_k_zscore_tokens(repetition2_zscore_attn_matrices, k=10, num_input_tokens=3*len(repetition2_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db7e03",
   "metadata": {},
   "source": [
    "## repetition summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_heads = 12\n",
    "\n",
    "repetition1_topk = get_top_k_zscore_tokens(repetition1_zscore_attn_matrices, k, 3*len(repetition1_notes))\n",
    "repetition2_topk = get_top_k_zscore_tokens(repetition2_zscore_attn_matrices, k, 3*len(repetition2_notes))\n",
    "\n",
    "repetition1_topk_notes, repetition1_topk_indices = get_note_stats_input(repetition1_topk, repetition1_notes)\n",
    "repetition2_topk_notes, repetition2_topk_indices = get_note_stats_input(repetition2_topk, repetition2_notes)\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    all_topk_notes = repetition1_topk_notes[i] + repetition2_topk_notes[i]\n",
    "    all_topk_indices = repetition1_topk_indices[i] + repetition2_topk_indices[i]\n",
    "\n",
    "    cur_head_repetition_summary = get_note_stats(all_topk_notes, all_topk_indices)\n",
    "    cur_head_repetition_summary.to_csv(f'repetition_summary_head{i}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de13cb6",
   "metadata": {},
   "source": [
    "# acc_mel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bbb44",
   "metadata": {},
   "source": [
    "## acc_mel1.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6468dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel1_midis = isolate_midi_tracks(\"acc_mel1/acc_mel1.mid\")\n",
    "\n",
    "acc_mel1_all_note_keys, acc_mel1_notes, acc_mel1_notes_per_track = process_midi_file(\"acc_mel1/acc_mel1.mid\", acc_mel1_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel1_notes, 0, len(acc_mel1_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 0 as melody\n",
    "modify_notes_by_track(acc_mel1_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel1_melody\"))\n",
    "# tag track 1 as accompaniment\n",
    "modify_notes_by_track(acc_mel1_notes_per_track, 1, lambda x: x.add_tag(\"acc_mel1_accompaniment\"))\n",
    "\n",
    "# tag first 8 accompaniment bars as arpeggio\n",
    "modify_notes_by_time_range(acc_mel1_notes_per_track[1], 0, 16.0, lambda x: x.add_tag(\"acc_mel1_arpeggio\"), in_ticks=False)\n",
    "\n",
    "# tag last 7 accompaniment bars as chords\n",
    "modify_notes_by_time_range(acc_mel1_notes_per_track[1], 16.0, 29.5, lambda x: x.add_tag(\"acc_mel1_chord\"), in_ticks=False)\n",
    "\n",
    "# for note in acc_mel1_notes:\n",
    "#     print(note)\n",
    "#     print(note.pitch)\n",
    "#     print(note.tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386af5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel1_attn_matrices = load_attn_matrices(\"acc_mel1.mid\", \"acc_mel1/acc_mel1_heads\")\n",
    "acc_mel1_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel1_attn_matrices)\n",
    "acc_mel1_zscore_attn_matrices, acc_mel1_attn_stats = rescale_attn_matrix_zscore(acc_mel1_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel1_topks = get_top_k_zscore_tokens(acc_mel1_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel1_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c313925",
   "metadata": {},
   "source": [
    "## acc_mel2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d202da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel2_midis = isolate_midi_tracks(\"acc_mel2/acc_mel2.mid\")\n",
    "\n",
    "acc_mel2_all_note_keys, acc_mel2_notes, acc_mel2_notes_per_track = process_midi_file(\"acc_mel2/acc_mel2.mid\", acc_mel2_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel2_notes, 0, len(acc_mel2_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 1 as melody\n",
    "modify_notes_by_track(acc_mel2_notes_per_track, 1, lambda x: x.add_tag(\"acc_mel2_melody\"))\n",
    "# tag track 0 as accompaniment\n",
    "modify_notes_by_track(acc_mel2_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel2_accompaniment\"))\n",
    "\n",
    "# tag first 8 accompaniment bars as arpeggio\n",
    "modify_notes_by_time_range(acc_mel2_notes_per_track[0], 0, 16.0, lambda x: x.add_tag(\"acc_mel2_arpeggio\"), in_ticks=False)\n",
    "\n",
    "# tag last 7 accompaniment bars as chords\n",
    "modify_notes_by_time_range(acc_mel2_notes_per_track[0], 16.0, 29.5, lambda x: x.add_tag(\"acc_mel2_chord\"), in_ticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64055d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel2_attn_matrices = load_attn_matrices(\"acc_mel2.mid\", \"acc_mel2/acc_mel2_heads\")\n",
    "acc_mel2_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel2_attn_matrices)\n",
    "acc_mel2_zscore_attn_matrices, acc_mel2_attn_stats = rescale_attn_matrix_zscore(acc_mel2_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel2_topks = get_top_k_zscore_tokens(acc_mel2_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel2_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f64a51",
   "metadata": {},
   "source": [
    "## acc_mel3.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel3_midis = isolate_midi_tracks(\"acc_mel3/acc_mel3.mid\")\n",
    "\n",
    "acc_mel3_all_note_keys, acc_mel3_notes, acc_mel3_notes_per_track = process_midi_file(\"acc_mel3/acc_mel3.mid\", acc_mel3_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel3_notes, 0, len(acc_mel3_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 0 as melody\n",
    "modify_notes_by_track(acc_mel3_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel3_melody\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel3_attn_matrices = load_attn_matrices(\"acc_mel3.mid\", \"acc_mel3/acc_mel3_heads\")\n",
    "acc_mel3_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel3_attn_matrices)\n",
    "acc_mel3_zscore_attn_matrices, acc_mel3_attn_stats = rescale_attn_matrix_zscore(acc_mel3_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel3_topks = get_top_k_zscore_tokens(acc_mel3_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel3_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af587446",
   "metadata": {},
   "source": [
    "## acc_mel4.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel4_midis = isolate_midi_tracks(\"acc_mel4/acc_mel4.mid\")\n",
    "\n",
    "acc_mel4_all_note_keys, acc_mel4_notes, acc_mel4_notes_per_track = process_midi_file(\"acc_mel4/acc_mel4.mid\", acc_mel4_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel4_notes, 0, len(acc_mel4_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 0 as accompaniment\n",
    "modify_notes_by_track(acc_mel4_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel4_accompaniment\"))\n",
    "\n",
    "# tag first 8 accompaniment bars as arpeggio\n",
    "modify_notes_by_time_range(acc_mel4_notes_per_track[0], 0, 16.0, lambda x: x.add_tag(\"acc_mel4_arpeggio\"), in_ticks=False)\n",
    "\n",
    "# tag last 7 accompaniment bars as chords\n",
    "modify_notes_by_time_range(acc_mel4_notes_per_track[0], 16.0, 29.5, lambda x: x.add_tag(\"acc_mel4_chord\"), in_ticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel4_attn_matrices = load_attn_matrices(\"acc_mel4.mid\", \"acc_mel4/acc_mel4_heads\")\n",
    "acc_mel4_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel4_attn_matrices)\n",
    "acc_mel4_zscore_attn_matrices, acc_mel4_attn_stats = rescale_attn_matrix_zscore(acc_mel4_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel4_topks = get_top_k_zscore_tokens(acc_mel4_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel4_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc15e18",
   "metadata": {},
   "source": [
    "## acc_mel5.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel5_midis = isolate_midi_tracks(\"acc_mel5/acc_mel5.mid\")\n",
    "\n",
    "acc_mel5_all_note_keys, acc_mel5_notes, acc_mel5_notes_per_track = process_midi_file(\"acc_mel5/acc_mel5.mid\", acc_mel5_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel5_notes, 0, len(acc_mel5_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 0 as melody (high)\n",
    "modify_notes_by_track(acc_mel5_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel5_melody_high\"))\n",
    "# tag track 1 as melody (low)\n",
    "modify_notes_by_track(acc_mel5_notes_per_track, 1, lambda x: x.add_tag(\"acc_mel5_melody_low\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c375a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel5_attn_matrices = load_attn_matrices(\"acc_mel5.mid\", \"acc_mel5/acc_mel5_heads\")\n",
    "acc_mel5_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel5_attn_matrices)\n",
    "acc_mel5_zscore_attn_matrices, acc_mel5_attn_stats = rescale_attn_matrix_zscore(acc_mel5_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel5_topks = get_top_k_zscore_tokens(acc_mel5_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel5_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f5df2",
   "metadata": {},
   "source": [
    "## acc_mel6.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "acc_mel6_midis = isolate_midi_tracks(\"acc_mel6/acc_mel6.mid\")\n",
    "\n",
    "acc_mel6_all_note_keys, acc_mel6_notes, acc_mel6_notes_per_track = process_midi_file(\"acc_mel6/acc_mel6.mid\", acc_mel6_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(acc_mel6_notes, 0, len(acc_mel6_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "\n",
    "# tag track 0 as accompaniment (high)\n",
    "modify_notes_by_track(acc_mel6_notes_per_track, 0, lambda x: x.add_tag(\"acc_mel6_accompaniment_high\"))\n",
    "# tag track 1 as accompaniment (low)\n",
    "modify_notes_by_track(acc_mel6_notes_per_track, 1, lambda x: x.add_tag(\"acc_mel6_accompaniment_low\"))\n",
    "\n",
    "# tag first 8 accompaniment bars as arpeggio (track 0)\n",
    "modify_notes_by_time_range(acc_mel6_notes_per_track[0], 0, 16.0, lambda x: x.add_tag(\"acc_mel6_arpeggio_high\"), in_ticks=False)\n",
    "# tag last 7 accompaniment bars as chords\n",
    "modify_notes_by_time_range(acc_mel6_notes_per_track[0], 16.0, 29.5, lambda x: x.add_tag(\"acc_mel6_chord_high\"), in_ticks=False)\n",
    "\n",
    "# tag first 8 accompaniment bars as arpeggio (track 1)\n",
    "modify_notes_by_time_range(acc_mel6_notes_per_track[1], 0, 16.0, lambda x: x.add_tag(\"acc_mel6_arpeggio_low\"), in_ticks=False)\n",
    "# tag last 7 accompaniment bars as chords\n",
    "modify_notes_by_time_range(acc_mel6_notes_per_track[1], 16.0, 29.5, lambda x: x.add_tag(\"acc_mel6_chord_low\"), in_ticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "acc_mel6_attn_matrices = load_attn_matrices(\"acc_mel6.mid\", \"acc_mel6/acc_mel6_heads\")\n",
    "acc_mel6_unif_attn_matrices = rescale_attn_matrix_unif(acc_mel6_attn_matrices)\n",
    "acc_mel6_zscore_attn_matrices, acc_mel6_attn_stats = rescale_attn_matrix_zscore(acc_mel6_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# acc_mel6_topks = get_top_k_zscore_tokens(acc_mel6_zscore_attn_matrices, k=10, num_input_tokens=3*len(acc_mel6_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e5e96",
   "metadata": {},
   "source": [
    "## acc_mel summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_heads = 12\n",
    "\n",
    "acc_mel1_topk = get_top_k_zscore_tokens(acc_mel1_zscore_attn_matrices, k, 3*len(acc_mel1_notes))\n",
    "acc_mel2_topk = get_top_k_zscore_tokens(acc_mel2_zscore_attn_matrices, k, 3*len(acc_mel2_notes))\n",
    "acc_mel3_topk = get_top_k_zscore_tokens(acc_mel3_zscore_attn_matrices, k, 3*len(acc_mel3_notes))\n",
    "acc_mel4_topk = get_top_k_zscore_tokens(acc_mel4_zscore_attn_matrices, k, 3*len(acc_mel4_notes))\n",
    "acc_mel5_topk = get_top_k_zscore_tokens(acc_mel5_zscore_attn_matrices, k, 3*len(acc_mel5_notes))\n",
    "acc_mel6_topk = get_top_k_zscore_tokens(acc_mel6_zscore_attn_matrices, k, 3*len(acc_mel6_notes))\n",
    "\n",
    "acc_mel1_topk_notes, acc_mel1_topk_indices = get_note_stats_input(acc_mel1_topk, acc_mel1_notes)\n",
    "acc_mel2_topk_notes, acc_mel2_topk_indices = get_note_stats_input(acc_mel2_topk, acc_mel2_notes)\n",
    "acc_mel3_topk_notes, acc_mel3_topk_indices = get_note_stats_input(acc_mel3_topk, acc_mel3_notes)\n",
    "acc_mel4_topk_notes, acc_mel4_topk_indices = get_note_stats_input(acc_mel4_topk, acc_mel4_notes)\n",
    "acc_mel5_topk_notes, acc_mel5_topk_indices = get_note_stats_input(acc_mel5_topk, acc_mel5_notes)\n",
    "acc_mel6_topk_notes, acc_mel6_topk_indices = get_note_stats_input(acc_mel6_topk, acc_mel6_notes)\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    all_topk_notes = acc_mel1_topk_notes[i] + acc_mel2_topk_notes[i] + acc_mel3_topk_notes[i] + acc_mel4_topk_notes[i] + acc_mel5_topk_notes[i] + acc_mel6_topk_notes[i] \n",
    "    all_topk_indices = acc_mel1_topk_indices[i] + acc_mel2_topk_indices[i] + acc_mel3_topk_indices[i] + acc_mel4_topk_indices[i] + acc_mel5_topk_indices[i] + acc_mel6_topk_indices[i]\n",
    "\n",
    "    cur_head_acc_mel_summary = get_note_stats(all_topk_notes, all_topk_indices)\n",
    "    cur_head_acc_mel_summary.to_csv(f'acc_mel_summary_head{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a976a77",
   "metadata": {},
   "source": [
    "# key_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b3bba",
   "metadata": {},
   "source": [
    "## key_change1.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdee718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "key_change1_midis = isolate_midi_tracks(\"key_change1/key_change1.mid\")\n",
    "\n",
    "key_change1_all_note_keys, key_change1_notes, key_change1_notes_per_track = process_midi_file(\"key_change1/key_change1.mid\", key_change1_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(key_change1_notes, 0, len(key_change1_notes)-1, lambda x: x.set_key_and_interval(56))\n",
    "# set key change notes\n",
    "modify_notes_by_time_range(key_change1_notes, 8.674704, 17.349408, lambda x: x.set_key_and_interval(63))\n",
    "\n",
    "# add key as tag\n",
    "modify_notes_by_time_range(key_change1_notes, 0, 8.674704, lambda x: x.add_tag(\"key_change1_key1\"))\n",
    "modify_notes_by_time_range(key_change1_notes, 8.674704, 17.349408, lambda x: x.add_tag(\"key_chang1_key2\"))\n",
    "\n",
    "# tag track 0 as melody\n",
    "modify_notes_by_track(key_change1_notes_per_track, 0, lambda x: x.add_tag(\"key_change1_melody\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "key_change1_attn_matrices = load_attn_matrices(\"key_change1.mid\", \"key_change1/key_change1_heads\")\n",
    "key_change1_unif_attn_matrices = rescale_attn_matrix_unif(key_change1_attn_matrices)\n",
    "key_change1_zscore_attn_matrices, key_change1_attn_stats = rescale_attn_matrix_zscore(key_change1_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# key_change1_topks = get_top_k_zscore_tokens(key_change1_zscore_attn_matrices, k=10, num_input_tokens=3*len(key_change1_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ef1d6",
   "metadata": {},
   "source": [
    "## key_change2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da63eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "key_change2_midis = isolate_midi_tracks(\"key_change2/key_change2.mid\")\n",
    "\n",
    "key_change2_all_note_keys, key_change2_notes, key_change2_notes_per_track = process_midi_file(\"key_change2/key_change2.mid\", key_change2_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(key_change2_notes, 0, len(key_change2_notes)-1, lambda x: x.set_key_and_interval(62))\n",
    "# set key change notes\n",
    "modify_notes_by_time_range(key_change2_notes, 8.0, 16.0, lambda x: x.set_key_and_interval(64))\n",
    "\n",
    "# add key as tag\n",
    "modify_notes_by_time_range(key_change2_notes, 0, 8.0, lambda x: x.add_tag(\"key_change2_key1\"))\n",
    "modify_notes_by_time_range(key_change2_notes, 8.0, 16.0, lambda x: x.add_tag(\"key_chang2_key2\"))\n",
    "\n",
    "# tag track 0 as melody\n",
    "modify_notes_by_track(key_change2_notes_per_track, 0, lambda x: x.add_tag(\"key_change2_melody\"))\n",
    "\n",
    "# tag track 1, 3, 4 as accompaniment\n",
    "modify_notes_by_track(key_change2_notes_per_track, 1, lambda x: x.add_tag(\"key_change2_accompaniment\"))\n",
    "modify_notes_by_track(key_change2_notes_per_track, 3, lambda x: x.add_tag(\"key_change2_accompaniment\"))\n",
    "modify_notes_by_track(key_change2_notes_per_track, 4, lambda x: x.add_tag(\"key_change2_accompaniment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ec608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "key_change2_attn_matrices = load_attn_matrices(\"key_change2.mid\", \"key_change2/key_change2_heads\")\n",
    "key_change2_unif_attn_matrices = rescale_attn_matrix_unif(key_change2_attn_matrices)\n",
    "key_change2_zscore_attn_matrices, key_change2_attn_stats = rescale_attn_matrix_zscore(key_change2_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# key_change2_topks = get_top_k_zscore_tokens(key_change2_zscore_attn_matrices, k=10, num_input_tokens=3*len(key_change2_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff32f0",
   "metadata": {},
   "source": [
    "## key_change summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c52c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_heads = 12\n",
    "\n",
    "key_change1_topk = get_top_k_zscore_tokens(key_change1_zscore_attn_matrices, k, 3*len(key_change1_notes))\n",
    "key_change2_topk = get_top_k_zscore_tokens(key_change2_zscore_attn_matrices, k, 3*len(key_change2_notes))\n",
    "\n",
    "key_change1_topk_notes, key_change1_topk_indices = get_note_stats_input(key_change1_topk, key_change1_notes)\n",
    "key_change2_topk_notes, key_change2_topk_indices = get_note_stats_input(key_change2_topk, key_change2_notes)\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    all_topk_notes = key_change1_topk_notes[i] + key_change2_topk_notes[i]\n",
    "    all_topk_indices = key_change1_topk_indices[i] + key_change2_topk_indices[i]\n",
    "\n",
    "    cur_head_summary = get_note_stats(all_topk_notes, all_topk_indices)\n",
    "    cur_head_summary.to_csv(f'key_change_summary_head{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46744caa",
   "metadata": {},
   "source": [
    "# fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425880c",
   "metadata": {},
   "source": [
    "## fast1.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "fast1_midis = isolate_midi_tracks(\"fast1/fast1.mid\")\n",
    "\n",
    "fast1_all_note_keys, fast1_notes, fast1_notes_per_track = process_midi_file(\"fast1/fast1.mid\", fast1_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(fast1_notes, 0, len(fast1_notes)-1, lambda x: x.set_key_and_interval(63))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "fast1_attn_matrices = load_attn_matrices(\"fast1.mid\", \"fast1/fast1_heads\")\n",
    "fast1_unif_attn_matrices = rescale_attn_matrix_unif(fast1_attn_matrices)\n",
    "fast1_zscore_attn_matrices, fast1_attn_stats = rescale_attn_matrix_zscore(fast1_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# fast1_topks = get_top_k_zscore_tokens(fast1_zscore_attn_matrices, k=10, num_input_tokens=3*len(fast1_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488cf19",
   "metadata": {},
   "source": [
    "## fast2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "fast2_midis = isolate_midi_tracks(\"fast2/fast2.mid\")\n",
    "\n",
    "fast2_all_note_keys, fast2_notes, fast2_notes_per_track = process_midi_file(\"fast2/fast2.mid\", fast2_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(fast2_notes, 0, len(fast2_notes)-1, lambda x: x.set_key_and_interval(65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e33ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "fast2_attn_matrices = load_attn_matrices(\"fast2.mid\", \"fast2/fast2_heads\")\n",
    "fast2_unif_attn_matrices = rescale_attn_matrix_unif(fast2_attn_matrices)\n",
    "fast2_zscore_attn_matrices, fast2_attn_stats = rescale_attn_matrix_zscore(fast2_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# fast2_topks = get_top_k_zscore_tokens(fast2_zscore_attn_matrices, k=10, num_input_tokens=3*len(fast2_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b08b7",
   "metadata": {},
   "source": [
    "## fast summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b10a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_heads = 12\n",
    "\n",
    "fast1_topk = get_top_k_zscore_tokens(fast1_zscore_attn_matrices, k, 3*len(fast1_notes))\n",
    "fast2_topk = get_top_k_zscore_tokens(fast2_zscore_attn_matrices, k, 3*len(fast2_notes))\n",
    "\n",
    "fast1_topk_notes, fast1_topk_indices = get_note_stats_input(fast1_topk, fast1_notes)\n",
    "fast2_topk_notes, fast2_topk_indices = get_note_stats_input(fast2_topk, fast2_notes)\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    all_topk_notes = fast1_topk_notes[i] + fast2_topk_notes[i]\n",
    "    all_topk_indices = fast1_topk_indices[i] + fast2_topk_indices[i]\n",
    "\n",
    "    cur_head_summary = get_note_stats(all_topk_notes, all_topk_indices)\n",
    "    cur_head_summary.to_csv(f'fast_summary_head{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c672d19",
   "metadata": {},
   "source": [
    "# slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0b4e9",
   "metadata": {},
   "source": [
    "## slow1.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b667b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "slow1_midis = isolate_midi_tracks(\"slow1/slow1.mid\")\n",
    "\n",
    "slow1_all_note_keys, slow1_notes, slow1_notes_per_track = process_midi_file(\"slow1/slow1.mid\", slow1_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(slow1_notes, 0, len(slow1_notes)-1, lambda x: x.set_key_and_interval(63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fdb1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "slow1_attn_matrices = load_attn_matrices(\"slow1.mid\", \"slow1/slow1_heads\")\n",
    "slow1_unif_attn_matrices = rescale_attn_matrix_unif(slow1_attn_matrices)\n",
    "slow1_zscore_attn_matrices, slow1_attn_stats = rescale_attn_matrix_zscore(slow1_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# slow1_topks = get_top_k_zscore_tokens(slow1_zscore_attn_matrices, k=10, num_input_tokens=3*len(slow1_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f05b3",
   "metadata": {},
   "source": [
    "## slow2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1a62e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MIDI FILE + PROCESS NOTES\n",
    "\n",
    "slow2_midis = isolate_midi_tracks(\"slow2/slow2.mid\")\n",
    "\n",
    "slow2_all_note_keys, slow2_notes, slow2_notes_per_track = process_midi_file(\"slow2/slow2.mid\", slow2_midis)\n",
    "\n",
    "# set key (and interval) for all notes\n",
    "modify_notes_by_index_range(slow2_notes, 0, len(slow2_notes)-1, lambda x: x.set_key_and_interval(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4861a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD + RESCALE ATTENTION MATRICES\n",
    "\n",
    "slow2_attn_matrices = load_attn_matrices(\"slow2.mid\", \"slow2/slow2_heads\")\n",
    "slow2_unif_attn_matrices = rescale_attn_matrix_unif(slow2_attn_matrices)\n",
    "slow2_zscore_attn_matrices, slow2_attn_stats = rescale_attn_matrix_zscore(slow2_attn_matrices)\n",
    "\n",
    "# STORE TOP K ATTENTION TOKENS PER MATRIX\n",
    "\n",
    "# slow2_topks = get_top_k_zscore_tokens(slow2_zscore_attn_matrices, k=10, num_input_tokens=3*len(slow2_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7615319",
   "metadata": {},
   "source": [
    "## slow summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62e197c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "num_heads = 12\n",
    "\n",
    "slow1_topk = get_top_k_zscore_tokens(slow1_zscore_attn_matrices, k, 3*len(slow1_notes))\n",
    "slow2_topk = get_top_k_zscore_tokens(slow2_zscore_attn_matrices, k, 3*len(slow2_notes))\n",
    "\n",
    "slow1_topk_notes, slow1_topk_indices = get_note_stats_input(slow1_topk, slow1_notes)\n",
    "slow2_topk_notes, slow2_topk_indices = get_note_stats_input(slow2_topk, slow2_notes)\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    all_topk_notes = slow1_topk_notes[i] + slow2_topk_notes[i]\n",
    "    all_topk_indices = slow1_topk_indices[i] + slow2_topk_indices[i]\n",
    "\n",
    "    cur_head_summary = get_note_stats(all_topk_notes, all_topk_indices)\n",
    "    cur_head_summary.to_csv(f'slow_summary_head{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
